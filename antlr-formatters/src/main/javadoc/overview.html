<!DOCTYPE html>
<html>
    <head>
        <title>Antlr Formatters API</title>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
    </head>
    <body>
        <h1>Antlr Formatters API</h1>
        <p>
            This package contains an API for describing how to modify the tokens
            in a source file parsed by Antlr in order to reformat that source
            file.  You create a set of
            <code><a href="FormattingRule.html">FormattingRule</a></code>s
            &mdash; your code is passed an empty
            <code><a href="FormattingRules.html">FormattingRules</a></code>
            instance to populate before formatting runs, and you can populate
            it with whatever rules you want to apply.  Each
            <code>FormattingRule</code> has a
            <code><a href="FormattingAction.html">FormattingAction</a></code>
            &mdash; the thing to do to the token being processed.  Simply adding a rule
            and a simple, built-in formatting action looks like this:
        </p>

        <pre>
rules.onTokenType( S_CLOSE_BRACE )
    .whereNextTokenTypeNot( S_SEMICOLON )
    .format( SimpleFormattingAction.APPEND_NEWLINE_AND_INDENT.by( BRACE_DEPTH ));
        </pre>
        <p>
            Formatters generally manipulate the amounts of whitespace between
            textual tokens in a language, and that is what this library is
            focused on.  But they may also rewrite tokens or reflow text, so
            token rewriting is supported too.
        </p>
        <p>
            Each <code>FormattingRule</code> has a set of <i>constraints</i>
            that determine whether it matches the current token.  <i><b>Exactly one</b>
                <code>FormattingRule</code> and <code>FormattingAction</code>
                will process any token</i>.  Constraints can be based on:
        </p>
        <ul>
            <li>The type of the current token</li>
            <li>The type of the preceding token</li>
            <li>The type of the susequent token</li>
            <li>The lexer mode (as defined in your Antlr grammar)</li>
            <li>Whether, in the input text, it was preceded or followed
                by a whitespace token containing a newline</li>
            <li>Much more complex constraints based on the
                <code><a href="LexingState.html">LexingState</a></code>,
                (see below), such as "only when in a group of braces
                with a nesting depth of 1", or "only when the distance
                to the next closing parenthesis is > 1" &mdash; since you
                program your LexingState to collect whatever you want,
                the sky is the limit with these.
            </li>
        </ul>
        <p>
            The IDs you use to identify token types and modes are all generated
            as static integer constants on your Antlr-based Lexer and Parser
            classes.
        </p>

        <h2>How to Approach Writing Formatters</h2>
        <p>
            As a general approach to writing formatters, start with the most
            general rules that will work almost everywhere - for example, things
            like "keywords always get a space before them and after them".  Try it (write a
            unit test that will print out text).  See where the rule is <i>too</i>
            general - for example, in Java, the rule just described would sometimes
            put a space before an end-of-line semicolon.  Then write more
            specific rules predicated on the preceding or next token type
            to fix those cases - since that rule will be more specific, it
            will win when competing against the more general one.
        </p>
        <p>
            Keep getting more specific until you hit a point where what you need
            cannot be solved with just knowing the preceding or next token - for
            example, indenting content within nested braces.  If, as in Java,
            there is a statement terminator character - '<code>;</code>', you
            can just set up your lexing state to increment the brace count on
            entering a <code>{</code> and decrement it on a <code>}</code>
            and use that.
        </p>
        <p>
            For cases that still isn't enough, you can either specify to run
            within a particular parser rule, or tell your
            <code><a href="LexingStateBuilder.html">LexingStateBuilder</a></code>
            to count the distance to the nearest instance of some other token
            type that only occurs at a specific distance in the case you want
            to handle, and condition your rule on that.
        </p>
        <p>
            Resist the temptation to start with those "ooh, I know I can do this
            cool thing" rules that are very specific, or it is easy to wind
            up with a very large formatting rule set most of which do more or
            less the same thing.  Start by looking for the most general cases
            that will handle the most tokens correctly, and then narrow down
            the corner cases - usually you will find generalities that aren't
            obvious until you're in the thick of it that work for a lot of cases.
        </p>

        <h3>How Tokens are Matched by Formatting Rules</h3>
        <p>
            Each <code>FormattingRule</code> gets a <b>specificity score</b> that
            determines the order it is tested against the current token, based on
            the number of constraints it contains.  Formatting rules attempt to
            match a token in order of specificity score, from highest to lowest.
            So a rule that matches a token type, and specifies that the next
            token must be another token type will win if it competes with a rule
            which is just matching any token of that type.
        </p>
        <p>
            There is one caveat to that:
            <i>specifying that a rule is specific to a particular
                parser rule id adds 1000 to its score</i>, since it is most common
            to write rules that run only when a particular parser rule is active,
            and to want these to take precedence. So parser rule specific
            formatting rules compete with each other at a different level than
            general rules - this is almost always what's desired.
        </p>
        <p>
            The specificity score is the number of kinds of constraints
            multiplied by 10, plus 1000 in the case of parser-rule-specific
            formatting rules.  In the case that there are two competing rules,
            and there is no way to make one more specific, you can call
            <code>priority(int)</code> on the rule you want to run first
            to increse (or decrease) its score by the amount passed, to
            guarantee which one will be tested first.
        </p>

        <h2>Formatting Actions</h2>
        <p>
            <code><a href="FormattingAction.html">FormattingAction</a></code>s
            perform modifications to the token being processed, which can consist
            of instructions to
        </p>
        <ul>
            <li>Prepend newlines and or whitespace</li>
            <li>Append newlines and or whitespace</li>
            <li>Rewrite the token text</li>
        </ul>
        <p>
            <code>FormattingAction</code>s can be combined.
            The enum
            <code><a href="SimpleFormattingAction.html">SimpleFormattingAction</a></code>
            predefines constants for common operations prepending or appending to
            the current token indenting or newlines.  The <code>FormattingAction</code>
            interface has default methods for combining instances with common
            operations such as trimming whitespace, reflowing text, and using LexingState
            values to determine the amount to indent.  For example, when configuring
            the lexing state:
        </p>
        <pre>
            stateBuilder.pushPosition(MyEnum.BRACE_POSITION)
                .onTokenType(MyLexer.OPEN_BRACE)
                .poppingOnTokenType(MyLexer.CLOSE_BRACE);
        </pre>
        and then using that value:
        <pre>
            FormattingAction indentToLastColonPosition =
                SimpleFormattingAction.PREPEND_NEWLINE_AND_INDENT.bySpaces(MyEnum.BRACE_POSITION);

            rules.onTokenType(ID).wherePreviousTokenType(SEMICOLON)
                .format(indentToLastColonPosition);
        </pre>

        <h2>LexingState &mdash; Automatically Indenting To The Right Depth and More</h2>
        <p>
            You would still have to do a lot of tedious work to handle different indent
            levels to format languages with nested sets of braces such as Java, were
            it not for the
            <code><a href="LexingState.html">LexingState</a></code>
            <code>LexingState</code>.  The other piece of initializing
            a formatter is programming its <code>LexingState</code> to collect the
            information you need, to automate decisions about how to indent.
            The <code>LexingState</code> is updated on every token before
            <code>FormattingRules</code> are applied.
            You create an <code>Enum</code> with constants named for what
            you want to collect, and describe the conditions to update them.
            It can be queried for integers and booleans at runtime, and actions
            and rules can be predicated on the value (or lack thereof).
            It can:
        </p>
        <ul>
            <li>Increment a counter whether one token type is encountered, and
                decrement it when a different token type is encountered, enabling
                you to do things like the example above's
                <code>format( SimpleFormattingAction.APPEND_NEWLINE_AND_INDENT.by(
                    BRACE_DEPTH) )</code>.  In that code <code>BRACE_DEPTH</code>
                is an enum constant <i>you define</i> &mdash; you then tell the
                <code>LexingStateBuilder</code> to update on <code>{</code>
                and <code>}</code> tokens like this:
                <pre>
stateBuilder.increment( BRACE_DEPTH ).onTokenType( S_OPEN_BRACE, S_OPEN_HINTS, S_OPEN_BRACKET )
        .decrementingWhenTokenEncountered( S_CLOSE_BRACE, S_CLOSE_HINTS, S_CLOSE_BRACKET );
                </pre>
            </li>
            <li>
                Record the position (in characters, in the modified source)
                from the beginning of the line of a particular token.  This lets
                you, for example, indent everything to the same position as
                a particular token in a preceding line (as Antlr grammars frequently
                do with the <code>:</code> character), optionally resetting
                when another kind of token is encountered.
            </li>
            <li>
                <i>Push</i> the position (in characters, in the modified source)
                from the beginning of the line of a particular token, popping
                on another token.
            </li>
            <li>Set a boolean under certain conditions and unset it on others</li>
            <li>
                Compute the distance to the nearest preceding or subsequent token
                of a particular type &mdash; frequently used to, for example, handle delimited
                lists of tokens such as a Java array &mdash; <code>{1, 2, 3, 4}</code> &mdash;
                differently for tokens in the middle of the array (for example,
                to allow line wrapping on those, but keep the <code>{1</code>
                and the <code>4}</code>together.
            </li>
        </ul>

        <h2>Example</h2>
        <p>
            Here is some example code from the unit tests for this project, to get a
            sense of what it looks like:
        </p>
        <pre>
private static final String MAX_LINE_LENGTH = "maxLineLength";

&#064;Override
protected void configure(LexingStateBuilder&lt;SLState, ?&gt; stateBuilder,
        FormattingRules rules, Preferences config) {

    stateBuilder.increment(BRACE_DEPTH)
            .onTokenType(S_OPEN_BRACE)
            .decrementingWhenTokenEncountered(S_CLOSE_BRACE);

    int maxLineLength = config.getInt(MAX_LINE_LENGTH, 80);

    FormattingAction doubleIndentForWrappedLines = APPEND_NEWLINE_AND_DOUBLE_INDENT
            .by(BRACE_DEPTH);

    FormattingAction indentCurrent = PREPEND_NEWLINE_AND_INDENT
            .by(BRACE_DEPTH)
            .wrappingLines(maxLineLength, doubleIndentForWrappedLines);

    FormattingAction indentSubseqeuent = APPEND_NEWLINE_AND_INDENT
            .by(BRACE_DEPTH)
            .wrappingLines(maxLineLength, doubleIndentForWrappedLines);

    FormattingAction doubleNewlineAndIndentIt
            = PREPEND_DOUBLE_NEWLINE_AND_INDENT.by(BRACE_DEPTH)
            .wrappingLines(maxLineLength, doubleIndentForWrappedLines);

    rules.onTokenType(K_TYPE)
            .whereNotFirstTokenInSource()
            .format(PREPEND_DOUBLE_NEWLINE);

    rules.onTokenType(LINE_COMMENT)
            .format(indentCurrent.and(indentSubseqeuent).trimmingWhitespace());

    rules.onTokenType(ID, QUALIFIED_ID)
            .wherePrevTokenType(K_IMPORT, K_NAMESPACE, K_TYPE)
            .format(PREPEND_SPACE);

    rules.onTokenType(ID)
            .whereNextTokenType(S_COLON)
            .format(indentCurrent);

    rules.onTokenType(ID, QUALIFIED_ID)
            .whereNextTokenTypeNot(S_SEMICOLON, S_COLON)
            .format(PREPEND_SPACE.and(APPEND_SPACE));

        </pre>

        <h2>Conditioning on Parser Rules</h2>
        <p>
            You can also write formatting rules which only operate when the
            token occurs inside of a particular parser rule, so as to have
            completely different formatting rules for one parser rule than
            another.  As mentioned, predicating a formatting rule on a parser
            will cause it to be tested before rules that do not specify
            a parser rule.
        </p>
        <p>
            Formatters which return null for the root <code>RuleNode</code>
            &mdash; i.e. they do not provide a parser &mdash; may not use such
            rules, and an exception will be thrown during formatting if they
            try.
        </p>
        <p>
            While conditioning on parser rules is powerful, don't make it your
            first choice.  You have the same information the parser does with
            the token stream you are processing, and frequently what's actually
            needed is far simpler than what the parser needs to do.  For example,
            say you wanted to ensure a space after the word "package" in a Java
            source.  You could just as easily specify that an identifier preceded
            by the token "package" always gets a space prepended.  Frequently
            there will be a number of similar circumstances (for example, the
            Java token "import" would want the same handling), and your
            formatting code will be simpler if you don't handle these on
            a parser-rule-by-parser-rule basis.  Also, for use in an IDE, the
            <i>the normal state of sources in an editor is <b>broken</b></i> -
            meaning if an <code>ErrorNode</code> is where the rule you
            expected is, whatever more general rules you have will be applied
            instead, which will probably do the wrong thing or introduce line
            changes a subsequent format with the source in a good state won't
            undo.  Writing against lexer rules only guarantees you don't write
            a formatter that can only properly format valid sources and
            wreaks havoc on invalid ones.
        </p>
        <h2>Coalescing of Prepend and Append</h2>
        <p>
            Formatting rules can prepend whitespace, or append whitespace,
            including adding newlines.  In practice, other than the last token
            in a document, all whitespace modifications are processed as
            prepend operations.  So it is possible for a rule for one token
            to specify to append something before the next token, and that
            next token might specify something contradictory.  For example,
            the preceding token might specify to append a newline, and the
            next to prepend a space.  The algorithm by which these are
            coalesced is as follows:
        </p>
        <ul>
            <li>Whitespace and newlines are coalesced separately &mdash; if one
                appends a newline, and the other indents, you get the
                newline and the indentation</li>
            <li>Single spaces get special handling &mdash; if one appends a newline
                and the other prepends a <i>single</i> space, the space is
                ignored; if indenting (&gt; 1 space append) is combined with
                a request for a multi-space indent, the single space is ignored.</li>
            <li>If both append contradictory numbers of spaces or newlines
                or both, you get the larger number of newlines and larger number
                of spaces from each</li>
            <li>Formatting rules can prepend or append spaces or tab-stops &mdash;
                these are compared on the basis of the number of spaces to decide
                which wins</li>
            <li>If both append the same number of spaces or newlines, you get
                that number of spaces or newlines &mdash; coalescing will never be
                additive for the same character</li>
        </ul>

        <h2>Debugging &amp; Logging</h2>
        <p>
            Your formatter can provide a <code>Predicate&lt;Token&gt;</code> to
            enable logging for a particular token type, and an ordered list
            of all of the rules applied to tokens of that time, if they don't
            match, the constraint that caused them not to match.
        </p>
        <p>
            The most common reason for formatting problems is having a rule
            with a higher priority and more general constraint (particular ones
            which operate on any token which is <i>not</i> some type).  The
            logging described above will tell you exactly which rules were
            tested and which one matched.
        </p>

        <h3>Loggability and Predicates</h3>
        <p>
            Logging only works for things that have a human-readable result
            from <code>toString()</code>.  Lambdas, though convenient, do not.
            The <code>Predicates</code> subtypes in this library all <i>do</i>
            implement <code>toString()</code> readably, and if you are debugging,
            you will want yours to as well.  Note the
            <code><a href="Criteria.html">Criteria</a></code>
            and
            <code><a href="Criterion.html">Criterion</a></code> classes,
            which will construct predicates given the array of token names
            from the generated Antlr lexer, and log the names of what's being
            looked for &mdash; it is far more useful than figuring out what it means
            when the token type is not <code>53</code>.
        </p>
        <h2>Implementing Formatting Actions</h2>
        <p>
            While the built in actions handle most needs, implementing the
            <code>FormattingAction</code> interface gives you full access
            to the lexing state, the token and its text, and the formatting
            context (which you call to prepend / append and query for the
            current position in the original and modified sources).  For
            example, here is how the simple line wrapping supported by
            <code>FormattingAction</code> is implemented:
        </p>
        <pre>
default FormattingAction wrappingLines(int limit, FormattingAction wrapAction) {
    return new FormattingAction() {
        &#064;Override
        public void accept(Token token, FormattingContext ctx, LexingState state) {
            if (ctx.currentCharPositionInLine() + token.getText().length() > limit) {
                wrapAction.accept(token, ctx, state);
            } else {
                FormattingAction.this.accept(token, ctx, state);
            }
        }

        &#064;Override
        public String toString() {
            return FormattingAction.this.toString() + "-wrap-at-" + limit
                    + "-with-" + wrapAction;
        }
    };
  }
        </pre>

        <h2>Advanced Predicates</h2>
        <p>
            Almost everything in processing tokens for formatting is
            based on the JDK's <code>IntPredicate</code>, which simply
            takes an <code>int</code> and returns a <code>boolean</code>.
            But don't let that simplicity fool you &mdash; it is possible to
            write predicates which maintain some state, and, say, respond
            with <code>true</code> only if the preceding tokens were a
            particular ordered sequence of values.  Just remember to recreate
            such predicates on every re-format so they don't retain state
            from a previous run.
        </p>
        <h2>Common Pitfalls</h2>
        <p>
            The order rules are processed in is critically important.  Rules are
            processed starting with the most specific, proceeding to the least
            specific, in the order they are added (calling toString() on a
            <code>FormattingRules</code> will show you the sequence they
            will be tested in).  Most problems outside of the obvious (the rule
            doesn't match what you think it does) fall into one of two categories:
        </p>
        <ul>
            <li>A more specific rule is capturing the thing you want processed by
                a less specific rule, and you need to:
                <ul>
                    <li>
                        Make the rule you want to capture the token
                        more specific - this is always preferable -
                        is there a lexer mode the lexer is always in when you want this
                        rule to apply?  Anything else?
                    </li>
                    <li>
                        Further constrain the more specific rule to avoid that
                        particular situation
                    </li>
                    <li>As a last resort, goose the rule that should capture this
                        with, say, <code>priority(30)</code>
                    </li>
                </ul>
            </li>
            <li>
                You want to turn <i>off</i> processing of a token in one very specific
                situation.   You could either
                <ul>
                    <li>
                        Make the rules in question more specific, or
                    </li>
                    <li>
                        Disable processing entirely (resulting in adjacent tokens
                        with no intervening whitespace) by creating a high-priority
                        rule that applies <code>FormattingAction.EMPTY</code>,
                        e.g.
                        <pre>
                            rules.onTokenType(ID).whereMode(someModePredicate)
                                .wherePreviousTokenType(SHARP).priority(100).
                                .format(FormattingAction.EMPTY)
                        </pre>
                    </li>
                </ul>
            </li>
            <li>You are depending on a value from <code>LexingState</code> which
                processing of the immediately previous token changed to something
                unexpected.  For example, Antlr language formatting offers a
                "floating indent" option that aligns rules under the colon of an
                Antlr rule - but of course, if a rule that puts that colon indented on a
                new line is present, nothing is going to "float" because the colon
                is always in the same place.
            </li>
            <li>
                You have a lot of rules and it is getting confusing.
                <ul>
                    <li>
                        Fewer rules is always easier to understand and debug.
                        Go back through the rules you've got, and see how
                        they can be generalized.  What are the <i>specific</i>
                        special cases?
                    </li>
                </ul>
            </li>
            <li>
                You have a rule which indents some token directly under another
                token on the previous line, and it <i>always</i> looks off-by-one,
                but when you print it to the command-line in a test, it works
                fine:
                <ul>
                    <li>You are using a monospaced font in the editor, right?
                        Are there any <i>boldface</i> tokens before the one
                        you want to align with in the preceding line?
                        Many fonts are "monospaced" but bold characters are
                        wider than plain characters.  Be sure this is not
                        happened, or switch to a font that does not have this
                        behavior, such as Courier, when testing.
                    </li>
                </ul>
            </li>
        </ul>
        <hr>
        <h1>Getting Started</h1>
        In source next to the antlr-formatters project is a project called
        simple-test-language, which includes an Antlr grammar for a trivial
        language that lets you define nested schemas for objects with a
        few simple types, sort of like what you might find in a JSON object.
        We will use that for this tutorial.
        <p>
            The first thing you will need is a NetBeans plugin project,
            with a dependency on <code>antlr-formatters</code> and some of
            its dependencies (if you use Maven, the first time you build,
            you will find out the missing dependencies).
        </p>
        <p>
            The <code>LexingState</code> is a sort of live database of
            things you define and can use for formatting (such as how
            deeply nested in braces a token is, or how many semicolons
            until the next closing brace, or the position of some preceding
            token).  So the first thing we will need is to define an
            <code>enum</code> to parameterize our implementation on - this enables formatting
            code to be easily human-readable, and the enum constants are the
            keys you will use to look things up in it.
        </p>
        <pre>
enum SLState {
    BRACE_DEPTH,
    BRACE_POSITION
}</pre>
        <p>
            The second step is to implement the interface <code>AntlrFormatterStub</code>,
            and annotate it so that layer.xml entries are generated.  It has one
            method you need to implement, <code>configure()</code> which is
            where you configure the formatting engine to do what you want.
            We will start with a single formatting rule which simply puts a
            space between all tokens in the source, with a few exceptions.
            This is our fallback rule which will capture any token none of the
            other rules we'll define catch.
        </p>
        <pre>
&#064;AntlrFormatterRegistration(mimeType=&quot;text/x-simple&quot;)
class SimpleFormatterStub implements AntlrFormatterStub&lt;SLState,SimpleLanguageLexer&gt; {
    public void configure(LexingStateBuilder&lt;SLState, ?> stateBuilder, FormattingRules rules, Preferences config) {
        // token types are constants Antlr generated as fields on your
        // lexer
        rules.onTokenTypeNot(S_SEMICOLON, S_CLOSE_BRACE, COMMENT, S_COMMA, S_CLOSE_PARENS)
                .whereNotFirstTokenInSource()
                .format(PREPEND_SPACE);
    }
}
        </pre>
        <p>
            This is enough to give us very minimal formatting - a few spaces
            and newlines.  We repeatedly call <code>rules.onTokenType</code>,
            which adds a new rule to the rule set;  we can then add constraints
            to when the rule is active;  finally we set the formatting action
            to call if this rule is matched.  So a parsing rule is a collection
            of tests to apply to tokens, with an associated action to modify the
            source if the tests pass.
        </p>
        <p>
            To test out what this does, we can create a unit test, and take
            advantage of antlr-formatting's test-jar library which makes it
            easy to write tests of formatters.  For now we'll use it as a
            way to develop our formatter and see its output;  later it can
            become the basis for tests of the results.
        </p>
        <p>
            Right click the file for your <code>SimpleFormatterStub</code>
            class, and choose <b>Tools | Create/Update Tests</b>, and
            accept the default options to create a test.
        </p>
        <p>
            Now we'll add a dependency on the test support JAR to make
            testing our formatter easy.  In you <code>pom.xml</code> file,
            add to the dependencies:
        </p>
        <pre>
&lt;dependency&gt;
    &lt;groupId&gt;${project.groupId}&lt;/groupId&gt;
    &lt;artifactId&gt;antlr-formatters&lt;/artifactId&gt;
    &lt;scope&gt;test&lt;/scope&gt;
    &lt;type&gt;test-jar&lt;/type&gt;
    &lt;version&gt;${project.version}&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.github.wumpz&lt;/groupId&gt;
    &lt;artifactId&gt;diffutils&lt;/artifactId&gt;
    &lt;version&gt;3.0&lt;/version&gt;
    &lt;scope&gt;test&lt;/scope&gt;
&lt;/dependency&gt;
        </pre>
        <p>
            Now add a test method to your class:
        </p>
        <pre>
    &#064;Test
    public void testSomeMethod() throws Exception {
        AntlrFormattingHarness&lt;Preferences, SLState&gt; harn
                = new AntlrFormattingHarness&lt;&gt;(SampleFiles.FORMATTING_TUTORIAL,
                        SimpleFormatterStub.class, SimpleLanguageLexer.S_WHITESPACE);
        String txt = harn.reformat();
        System.out.println("FORMATTED:\n" + txt);
    }
        </pre>
        <p>
            That is enough to format a file.  We are using the SampleFiles
            enum from the simple language project, which provides a set of
            test files to format, and implements the <code>SampleFile</code>
            interface - you can implement a similar enum of sample files for
            testing any language formatter.  We create an
            <code>AntlrFormattingHarness</code>, which takes care of setting
            up formatting infrastructure, providing it with three things:
        </p>
        <ol>
            <li>The sample file to format</li>
            <li>The enum class</li>
            <li>One or more tokens that signify whitespace - the formatting
                engine will skip over these, deleting them as we rewrite
                whitespace in the document</li>
        </ol>
        <p>
            If we run our test, the output isn't pretty, but it shows
            our rule in action:
        </p>
        <pre>
types Stuff; person : object { **This item has a description
 place : object { thing : object { // A line comment here
 otherThing : object { ** a multi line
 ** description
 ratio : float default 23.42; name : string default &quot;Formatting is fun&quot;; math :
                                int default 3 + 2 + 7 + 8 * 26 - ( 5 + 3 * 18) /
                                12;/* We support block comments as well, and the formatting engine supports
reflowing their content or rewriting it.
*/ array : intArray default [ 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65,
                                70, 75, 80, 85, 90, 95, 100 ];}}}}
        </pre>
        <p>
            Now, this file format has a nested structure, so we will want the
            ability to indent based on how nested a token starting a line is.
            For that, we need to program our <code>LexingState</code> to
            collect some information about nesting for us.  Add the following
            to the <code>configure()</code> method:
        </p>
        <pre>
            stateBuilder.increment(BRACE_DEPTH)
                    .onTokenType(S_OPEN_BRACE)
                    .decrementingWhenTokenEncountered(S_CLOSE_BRACE);
        </pre>
        <p>
            This will increment a counter every time we pass an <code>{</code>
            character and decrement it on every <code>}</code>.  With one
            more rule, we can put that to work, indenting our code.  Since we
            want this rule and all the others to be matched in preference
            to the fallback rule, we will define a separate layer this next
            rule and all the others will live in, which ensures they are
            tested first:
        </p>
        <pre>
    rules.layer(rls -&gt; {
        rls.onTokenType(ID, LINE_COMMENT, DESCRIPTION, COMMENT)
                .wherePreviousTokenType(S_SEMICOLON, S_OPEN_BRACE, 
                        S_CLOSE_BRACE, LINE_COMMENT, COMMENT, DESCRIPTION)
                .format(PREPEND_NEWLINE_AND_INDENT.by(BRACE_DEPTH));
    });
        </pre>
        <p>
            Running the test again, now our output looks more like something
            intentionally formatted:
        </p>
        <pre>
types Stuff;
person : object {
    **This item has a description

    place : object {
        thing : object {
            // A line comment here

            otherThing : object {
                ** a multi line

                ** description

                ratio : float default 23.42;
                name : string default &quot;Formatting is fun&quot;;
                math : int default 3 + 2 + 7 + 8 * 26 - ( 5 + 3 * 18) / 12;
                /* We support block comments as well, and the formatting engine supports
reflowing their content or rewriting it.
*/
                array : intArray default [ 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100 ];}}}}
        </pre>
        <p>
            You'll notice something odd has happened:  Some things are separated
            by blank lines.  This is because two rules, <code>DESCRIPTION</code>
            and <code>LINE_COMMENT</code> are both Antlr rules which capture
            everything up to the end of the line, so they wind up including the
            newline that terminates the line - that will happen with any such
            Antlr rule.  So we need to modify our formatting rule slightly,
            adding a call to <code>.trimmingWhitespace()</code> to the
            formatting action:
        </p>
        <pre>
        rls.onTokenType(ID, LINE_COMMENT, DESCRIPTION, COMMENT)
                .wherePreviousTokenType(S_SEMICOLON, S_OPEN_BRACE, S_CLOSE_BRACE, 
                    LINE_COMMENT, COMMENT, DESCRIPTION)
                .format(PREPEND_NEWLINE_AND_INDENT.by(BRACE_DEPTH)
                    .trimmingWhitespace();
        </pre>
        <p>
            That will eliminate the spurious newlines, and give us full control
            over the placement of line breaks.  While we're changing things,
            let's take care of line-wrapping while we're at it, by having our
            fallback rule's <code>FormattingAction</code> delegate to another
            one if the line length goes above a certain length:
        </p>
        <pre>
    rules.onTokenTypeNot(S_SEMICOLON, S_CLOSE_BRACE, COMMENT, S_COMMA, S_CLOSE_PARENS)
            .whereNotFirstTokenInSource()
            .format(PREPEND_SPACE.wrappingLines(80, 
                    PREPEND_NEWLINE_AND_DOUBLE_INDENT.by(BRACE_DEPTH)));
        </pre>
        <p>
            Once we have a UI for configuring formatting, we can get the
            wrap point from the <code>Preferences</code> passed into this
            method, instead of hard-coding it to <code>80</code>.
        </p>
        <p>
            The last time we ran the formatter, all of the closing <code>}</code>
            characters were piled up at the end of the last line, so let's add
            a rule to take care of that now:
        </p>
        <pre>
        rls.onTokenType(S_CLOSE_BRACE)
                .format(PREPEND_NEWLINE_AND_INDENT.by(BRACE_DEPTH));
        </pre>
        <p>
            That get's us output that is starting to look pretty good:
        </p>
        <pre>
types Stuff;
person : object {
    **This item has a description
    place : object {
        thing : object {
            // A line comment here
            otherThing : object {
                ** a multi line
                ** description
                ratio : float default 23.42;
                name : string default &quot;Formatting is fun&quot;;
                math : int default 3 + 2 + 7 + 8 * 26 - ( 5 + 3 * 18) / 12;
                /* We support block comments as well, and the formatting engine supports
reflowing their content or rewriting it.
*/
                array : intArray default [ 5, 10, 15, 20, 25, 30, 35, 40, 45, 50,
                                55, 60, 65, 70, 75, 80, 85, 90, 95, 100 ];
            }
        }
    }
}</pre>
        <p>
            There are a couple of things we could do to improve things - the
            block comment is still formatted oddly, and it would be nice to
            call out items with a description by placing a blank line before
            them:
        </p>
        <pre>
        rls.onTokenType(DESCRIPTION)
                .priority(100)
                .wherePreviousTokenTypeNot(DESCRIPTION)
                .format(PREPEND_DOUBLE_NEWLINE_AND_INDENT.by(BRACE_DEPTH).trimmingWhitespace());

        rls.onTokenType(COMMENT)
                .priority(100)
                .format(PREPEND_NEWLINE_AND_INDENT
                        .by(BRACE_DEPTH)
                        .rewritingTokenTextWith(
                                TokenRewriter.simpleReflow(80)));
        </pre>
        <p>
            At this point, we have pretty nice looking output:
        </p>
        <pre>
types Stuff;
person : object {

    **This item has a description
    place : object {
        thing : object {
            // A line comment here
            otherThing : object {

                ** a multi line
                ** description
                ratio : float default 23.42;
                name : string default &quot;Formatting is fun&quot;;
                math : int default 3 + 2 + 7 + 8 * 26 - ( 5 + 3 * 18) / 12;
                /* We support block comments as well, and the formatting engine
                supports reflowing their content or rewriting it. */
                array : intArray default [ 5, 10, 15, 20, 25, 30, 35, 40, 45, 50,
                                55, 60, 65, 70, 75, 80, 85, 90, 95, 100 ];
            }
        }
    }
}</pre>
        <p>
            But we also have the flexibility, thinks to <code>LexingState</code>'s
            ability to capture token positions, the ability to do more advanced,
            and sometimes more aesthetically pleasing things.  Say we want to 
            indent everything related to some token underneath its exact
            character position (one of the options for the Antlr grammar language
            formatter is to align everything under the <code>:</code> character,
            and uses this option).  Let's change things around to capture the 
            position of the most recent <code>{</code> character.  We will use
            another of our enum constants:
        </p>
        <pre>
            stateBuilder.pushPosition(BRACE_POSITION)
                    .onTokenType(S_OPEN_BRACE)
                    .poppingOnTokenType(S_CLOSE_BRACE);
        </pre>
        <p>
            We will modify our formatting actions, as follows:  Where 
            before we were calling <code>.by(BRACE_DEPTH)</code>, which
            was prepending four spaces for each step of depth, now we need
            to indent by spaces: <code>.bySpaces(BRACE_POSITION)</code>.
        </p>
        <p>
            Since we perform the same formatting operations in several places,
            this is a good time to define these each as a variable, so that,
            if we wanted to make this kind of formatting an option, we could
            simply set them up differently depending on a the settings in the
            <code>Preferences</code> passed in to the <code>configure()</code>
            method.  So here is the entire rewritten method:
        </p>
        <pre>
        &#064;Override
        public void configure(LexingStateBuilder&lt;SLState, ?&gt; stateBuilder,
                FormattingRules rules, Preferences config) {

            stateBuilder.increment(BRACE_DEPTH)
                    .onTokenType(S_OPEN_BRACE)
                    .decrementingWhenTokenEncountered(S_CLOSE_BRACE);

            stateBuilder.pushPosition(BRACE_POSITION)
                    .onTokenType(S_OPEN_BRACE)
                    .poppingOnTokenType(S_CLOSE_BRACE);

            FormattingAction onNextLine
                    = PREPEND_NEWLINE_AND_INDENT
                            .bySpaces(BRACE_POSITION);

            FormattingAction onNextLineTrimmed
                    = PREPEND_NEWLINE_AND_INDENT
                            .bySpaces(BRACE_POSITION)
                            .trimmingWhitespace();

            FormattingAction doubleNewline
                    = PREPEND_DOUBLE_NEWLINE_AND_INDENT
                            .bySpaces(BRACE_POSITION)
                            .trimmingWhitespace();

            FormattingAction doubleIndent = PREPEND_NEWLINE_AND_INDENT
                    .bySpaces(4, BRACE_POSITION);

            FormattingAction spaceOrWrap
                    = PREPEND_SPACE.wrappingLines(80, doubleIndent);

            rules.onTokenTypeNot(S_SEMICOLON, S_CLOSE_BRACE, COMMENT,
                    S_COMMA, S_CLOSE_PARENS)
                    .whereNotFirstTokenInSource()
                    .format(spaceOrWrap);

            rules.layer(rls -&gt; {
                rls.onTokenType(ID, LINE_COMMENT, DESCRIPTION, COMMENT)
                        .wherePreviousTokenType(S_SEMICOLON, S_OPEN_BRACE,
                                S_CLOSE_BRACE, LINE_COMMENT, COMMENT,
                                DESCRIPTION)
                        .format(onNextLineTrimmed);

                rls.onTokenType(S_CLOSE_BRACE).format(onNextLine);

                rls.onTokenType(DESCRIPTION)
                        .wherePreviousTokenTypeNot(DESCRIPTION)
                        .format(doubleNewline);

                rls.onTokenType(COMMENT)
                        .priority(100)
                        .format(onNextLine
                                .rewritingTokenTextWith(
                                        TokenRewriter.simpleReflow(80)));
            });
        }
    }</pre>
        <p>
            Whether the output is aesthetically pleasing or not is an exercise
            for the reader, but the results certainly point out the flexibility
            of this model:
        </p>
        <pre>
types Stuff;
person : object {

                **This item has a description
                place : object {
                               thing : object {
                                              // A line comment here

                                              ** a multi line
                                              ** description
                                              ratio : float default 23.42;
                                              name : string default
                                                  &quot;Formatting is fun&quot;;
                                              math : int default 3 + 2 + 7 + 8 *
                                                  26 - ( 5 + 3 * 18) / 12;
                                              /* We support block comments as
                                              well, and the formatting engine
                                              supports reflowing their content or
                                              rewriting it. */
                                              array : intArray default [ 5, 10,
                                                  15, 20, 25, 30, 35, 40, 45, 50,
                                                  55, 60, 65, 70, 75, 80, 85, 90,
                                                  95, 100 ];
                                              }
                               }
                }           
        </pre>
        <h2>Writing Tests for Formatters</h2>
        <p>
            Above, we used a unit test as the skeleton for developing our
            formatter.  Now let's turn that into a real unit test.
        </p>
        <p>
            The key thing to test in formatters is whether the formatter output
            has changed in unexpected way - it is easy to add a new rule to add some
            nuance to the formatting, and discover only later that in certain
            cases, it will alter the formatting of things you didn't expect.
        </p>
        <p>
            <code>GoldenFiles</code> in the <code>test-jar</code> artfiact of
            <code>antlr-formatters</code> makes it trivial to create such
            tests.  Since we are using an <code>enum</code> which implements
            <code>SampleFile</code>, it is trivial to write a test which will
            format each file in the enum, and either save it into the project's
            test resources directory, or load an existing file and compare the
            output:
        </p>
        <pre>
    private static GoldenFiles&lt;?, ?, SimpleLanguageLexer, Preferences&gt; goldenFiles;

    &#064;EnumSource(SampleFiles.class)
    &#064;ParameterizedTest(name = &quot;test-[{arguments}]&quot;)
    public void testSomeMethod(SampleFiles file) throws Exception {
        MockPreferences prefs = MockPreferences.of(MAX_LINE_LENGTH, 80);
        String filename = prefs.filename(file.name().toLowerCase() + &quot;-&quot;, &quot;sim&quot;);
        goldenFiles.test(file, prefs, filename, false);
    }

    &#064;BeforeAll
    public static void setup() throws URISyntaxException {
        goldenFiles = new GoldenFiles&lt;&gt;(DemoDev.class, SimpleFormatterStub.class,
                S_WHITESPACE);
    }</pre>
        <p>
            This test will:
        </p>
        <ul>
            <li>Iterate over every enum entry in <code>SampleFiles</code> and
                <ul>
                    <li>Format the file using our formatter</li>
                    <li>Re-lex the output and fail if syntax errors are encountered</li>
                    <li>Look for a file with the passed name, and
                        <ul>
                            <li>If it does <i>not</i> exist, create it</li>
                            <li>If it <i>does</i> exist, compare the output 
                                character-for-character with the that file,
                                and print a nice, readable diff of what changed
                                if something did
                            </li>
                        </ul>
                    </li>
                </ul>
            </li>
        </ul>
        <p>
            The <code>GoldenFiles</code> constructor that takes a 
            <code>Class&lt;?&gt;</code> for the first argument will put
            golden files in the Maven test resource directory for the
            corresponding package.  If you want to put them somewhere else,
            simply use the constructor which takes a Path instead.
        </p>
    </body>
</html>
